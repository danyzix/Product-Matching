{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first model, a baseline model which uses a simple TF-IDF character classification model based on character level 1 to 3 ngrams to map the retailer sequence to the most similar manufacturer sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time\n",
    "from pandas.io.json import json_normalize\n",
    "import string, pickle\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change the file_dir to your working directory to read the file\n",
    "file_dir = '/home/danyzix/Dissertation/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling functions to save and load lists\n",
    "def pickle_save(data, name):\n",
    "    path = os.path.join(file_dir, '{}.pkl'.format(name))\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=-1)\n",
    "        f.close()\n",
    "def pickle_open(name):\n",
    "    path = os.path.join(file_dir, '{}.pkl'.format(name))\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_pairs3 = pickle_open('rb_pairs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique texts and update a Counter from a list\n",
    "def get_unique_texts(data, row):\n",
    "    temp_text = []\n",
    "    for i in range(len(data)):\n",
    "        temp_text.append(data[i][row])\n",
    "    counter = collections.Counter(temp_text)               # add a counter to count the frequency of texts in the brand texts\n",
    "    unique_text = list(set(temp_text))                     # form a set of unique texts for the data\n",
    "    return counter, unique_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67457 retailer sequences have only 60790 unique sequences\n"
     ]
    }
   ],
   "source": [
    "# get the unique texts from the retailer sequences\n",
    "retailer_sequence_counter, unique_retailer_sequence = get_unique_texts(rb_pairs3, 0)\n",
    "\n",
    "print('{} retailer sequences have only {} unique sequences'.format(len(rb_pairs3), len(unique_retailer_sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24645,\n",
       " ['lg electronics 32 class qhd led ips monitor radeon freesync 31.5 diagonal 32qk500w',\n",
       "  1531971])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the manufacturer sequence-productIDmapping file\n",
    "text_product_map = pickle_open('unique_brand_text_product_mapping')\n",
    "len(text_product_map), text_product_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60790, 24645, 85435)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form an evaluation corpus from unique_retailer_sequence + text_product_map\n",
    "eval_corpus = unique_retailer_sequence.copy()\n",
    "for i in range(len(text_product_map)):\n",
    "    eval_corpus.append(text_product_map[i][0])\n",
    "    \n",
    "len(unique_retailer_sequence), len(text_product_map), len(eval_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF_Box to store all cosine similarity scores between unique_retailer_sequence and manufacturer sequence\n",
    "def TFIDF_Box(corpus):\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3), min_df = 0)\n",
    "    tfidf_matrix =  tfidf_vectorizer.fit_transform(corpus)\n",
    "    # build the box to store all TF-IDF cosine similarity values\n",
    "    start = time.time()\n",
    "    print('number of rows to be processed: {}'.format(len(unique_retailer_sequence)))\n",
    "    TFIDF_box = []\n",
    "    for i in range(len(unique_retailer_sequence)):\n",
    "        cosine_similarities = linear_kernel(tfidf_matrix[i], tfidf_matrix[len(unique_retailer_sequence):]).flatten()\n",
    "        related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "        related_products = [text_product_map[a][1] for a in related_docs_indices]\n",
    "        cosine_similarities = cosine_similarities[related_docs_indices]\n",
    "        TFIDF_box.append([unique_retailer_sequence[i], related_products, cosine_similarities, related_docs_indices ])\n",
    "        if i%5000==0:\n",
    "            print('processed {} products, time elapsed:{} seconds'.format(i+1, (time.time() - start)))\n",
    "    print('complete')\n",
    "    return TFIDF_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy and store correct and wrong predictions\n",
    "def accuracy_calcluator(model_box, pred_pairs, lookup_pairs):\n",
    "    n_correct_predictions = 0\n",
    "    correct_predictions = []\n",
    "    wrong_predictions = []\n",
    "    for i in range(len(pred_pairs)):\n",
    "        predicted_product = [a[1][0] for a in model_box if a[0] == pred_pairs[i][0]][0]\n",
    "        if predicted_product == lookup_pairs[i][2]:            \n",
    "            correct_predictions.append([i, lookup_pairs[i][0], lookup_pairs[i][1],\n",
    "                                        pred_pairs[i][0], predicted_product, lookup_pairs[i][2]])\n",
    "        else:\n",
    "            wrong_predictions.append([i, lookup_pairs[i][0], lookup_pairs[i][1],\n",
    "                                        pred_pairs[i][0], predicted_product, lookup_pairs[i][2]])\n",
    "            \n",
    "    return correct_predictions, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows to be processed: 60790\n",
      "processed 1 products, time elapsed:0.3663780689239502 seconds\n",
      "processed 5001 products, time elapsed:541.273736000061 seconds\n",
      "processed 10001 products, time elapsed:908.7083175182343 seconds\n",
      "processed 15001 products, time elapsed:1274.9415078163147 seconds\n",
      "processed 20001 products, time elapsed:1641.217788696289 seconds\n",
      "processed 25001 products, time elapsed:2008.5817806720734 seconds\n",
      "processed 30001 products, time elapsed:2378.516968011856 seconds\n",
      "processed 35001 products, time elapsed:2746.4461603164673 seconds\n",
      "processed 40001 products, time elapsed:3115.1013584136963 seconds\n",
      "processed 45001 products, time elapsed:3483.051223754883 seconds\n",
      "processed 50001 products, time elapsed:3852.707444667816 seconds\n",
      "processed 55001 products, time elapsed:4224.314737796783 seconds\n",
      "processed 60001 products, time elapsed:4596.331452846527 seconds\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# build the TFIDF_box to store all the cosine similarity values\n",
    "TFIDF_box = TFIDF_Box(eval_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.05%\n"
     ]
    }
   ],
   "source": [
    "# separate the right and wrong predictions for the overall prediction and calculate the accuracy \n",
    "tfidf_overall_CP, tfidf_overall_WP = accuracy_calcluator(TFIDF_box, rb_pairs3, rb_pairs3)\n",
    "print('accuracy: {0:.2f}%'.format(int(len(tfidf_overall_CP))/int(len(rb_pairs3))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
